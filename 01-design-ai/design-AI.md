## #1. _Name a real-world example of an existing AI system that is problematic in that it actually enacts existing problematic social systems/practices._ ##

One of the AI systems that currently enacts some of these issues would be facial recognition systems. These systems are used by law enforcement to help with the identification of individuals. Facial recognition systems have been shown to have significant bias when misidentifying individuals from certain racial and ethnic backgrounds, age groups, and gender identities. Some systems have been shown to have difficulties in differentiating between two different black men as opposed to two different white men, for example.

## #2. _Describe this system in terms of (your perceived high-level) **goals**, **environment**, and **adaptations** of the system._
**Goals**
* Analyze the images of the face of suspects
* Compare faces against large database of faces it was trained on
* Recreate a new database of faces based on the submitted image for law enforcement to use in their search
* Compare faces to possible matches already in the system

**Environment**
* Various locations where the data is stored and monitored
* Government owned machines for use by law enforcement
* Database of faces
* Database of newly generated faces
* Percentages that indicate a "percent match"

**Adaptations**
* Change race of suspect based on submition photo(s)
* Change hair color of suspect based on submition photo(s)
* Change nostril width based on submition photo(s)
* Compare image against mugshots vs selfies

## #3. _Describe a potential reimagined system in terms of goals, environment, and adaptations. How does it improve upon the system described in 2?_

**Goals**
* Analyze the images of the face of suspects
* Compare faces against large database of faces it was trained on

	-Train the model on a large database of faces
 
	-Use a large group of very diverse faces in a variety of light levels
 
* Recreate a new database of faces based on the submitted image for law enforcement to use in their search
* Compare faces to possible matches already in the system

	-Add in a manual review (if not already in place like most systems should have)

**Environment**
* Various locations where the data is stored and monitored
* Government owned machines for use by law enforcement

	-Allow citizens to have access to the technology for transparency
 
* Database of faces
* Database of newly generated faces
* Numbers that indicate a "percent match"

	-Ensure the model is functioning properly through human review and feedback

**Adaptations**
* Change race of suspect based on submition photo(s)
* Change hair color of suspect based on submition photo(s)
* Change nostril width based on submition photo(s)
* Compare image against mugshots vs selfies

	-Every time a photo is submitted to the system, it adapts to the facial features of the person. Historically, some systems have had more issues differentiating between two black men as opposed to two white men. These systems should be trained on a wide diverse range of faces so that they can more effectively adapt to recreating what a suspects face might look like, regardless of race, gender, ethnicity, etc. 
 
	-Providing more data to train on that includes a wider variety of camera angles, lighting, and resolutions will also help considerably.
